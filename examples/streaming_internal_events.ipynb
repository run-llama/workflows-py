{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6128a94",
   "metadata": {},
   "source": [
    "# Streaming Internal Events\n",
    "\n",
    "Event streaming is intrisinc to workflows and very easy to implement, as you can see in this example code:\n",
    "\n",
    "```python\n",
    "class SpecialEvent(Event):\n",
    "    pass\n",
    "\n",
    "class OtherEvent(Event):\n",
    "    pass\n",
    "\n",
    "class MyWorkflow(Workflow):\n",
    "    ...\n",
    "\n",
    "wf = MyWorkflow(...)\n",
    "\n",
    "handler = wf.run()\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, SpecialEvent):\n",
    "        print(\"This is a special event, hurray!\")\n",
    "    else:\n",
    "        print(\"Not a special event :(\")\n",
    "```\n",
    "\n",
    "Beyond streaming user-defined events, workflows can also stream internal events, such as changes in the state of the current step, input and output events, modifications of the workflow state and variation in the content of internal queues.\n",
    "\n",
    "In the following example, we will see how we can leverage internal events streaming to expose details about the current workflow execution - while the workflow is running!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2e4e6",
   "metadata": {},
   "source": [
    "## 1. Install needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7601894",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-workflows llama-cloud-services llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b991bab",
   "metadata": {},
   "source": [
    "## 2. Define events, workflow state and resources\n",
    "\n",
    "In order for our workflow to work, we will need three things:\n",
    "\n",
    "- Events classes defining the flow\n",
    "- A workflow state representation\n",
    "- External resources to inject into the workflow when needed\n",
    "\n",
    "We will build a workflow that takes a document as input, extracts its raw text content and returns a summary based on that text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0275eb8e",
   "metadata": {},
   "source": [
    "### 2.1 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1468c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows.events import Event, StartEvent, StopEvent\n",
    "\n",
    "\n",
    "class InputDocumentEvent(StartEvent):\n",
    "    document_path: str\n",
    "    summary_prompt: str\n",
    "\n",
    "\n",
    "class ParsedDocumentEvent(Event):\n",
    "    document_content: str\n",
    "\n",
    "\n",
    "class SummaryEvent(StopEvent):\n",
    "    document_summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03092946",
   "metadata": {},
   "source": [
    "### 2.2 State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb90c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class WorkflowState(BaseModel):\n",
    "    summary_prompt: str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd34ee",
   "metadata": {},
   "source": [
    "### 2.3 Resources\n",
    "\n",
    "For resources, we will use LlamaParse as a document parser, so you will need to set a `LLAMA_CLOUD_API_KEY` in your environment. If you do not have a LlamaCloud API key, you can [get one here](https://cloud.llamaindex.ai).\n",
    "\n",
    "Also, you will need an OpenAI API key to use GPT-5 as a document summarizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393a057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.llms.openai import OpenAIResponses\n",
    "\n",
    "\n",
    "async def get_document_parser(*args, **kwargs) -> LlamaParse:\n",
    "    # we will use LlamaParse in agentic mode\n",
    "    return LlamaParse(\n",
    "        parse_mode=\"parse_page_with_agent\",\n",
    "        model=\"openai-gpt-4-1-mini\",\n",
    "        high_res_ocr=True,\n",
    "        adaptive_long_table=True,\n",
    "        outlined_table_extraction=True,\n",
    "        output_tables_as_HTML=True,\n",
    "        result_type=\"markdown\",\n",
    "    )\n",
    "\n",
    "\n",
    "async def get_llm_summary(*args, **kwargs) -> OpenAIResponses:\n",
    "    return OpenAIResponses(model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f1ae",
   "metadata": {},
   "source": [
    "## 3. Define the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d5d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import Workflow, Context, step\n",
    "from workflows.resource import Resource\n",
    "from typing import Annotated\n",
    "\n",
    "\n",
    "class SummaryWorkflow(Workflow):\n",
    "    @step\n",
    "    async def get_document_content(\n",
    "        self,\n",
    "        ev: InputDocumentEvent,\n",
    "        ctx: Context[WorkflowState],\n",
    "        document_parser: Annotated[LlamaParse, Resource(get_document_parser)],\n",
    "    ) -> ParsedDocumentEvent:\n",
    "        async with ctx.store.edit_state() as state:\n",
    "            state.summary_prompt = ev.summary_prompt\n",
    "        result = await document_parser.aparse(ev.document_path)\n",
    "        content = []\n",
    "        if isinstance(result, list):\n",
    "            for r in result:\n",
    "                content.extend((await r.aget_markdown_documents()))\n",
    "        else:\n",
    "            content.extend((await result.aget_markdown_documents()))\n",
    "        text_content = \"\"\n",
    "        for document in content:\n",
    "            text_content += document.text + \"\\n\\n---\\n\\n\"\n",
    "        ctx.write_event_to_stream(ParsedDocumentEvent(document_content=text_content))\n",
    "        return ParsedDocumentEvent(document_content=text_content)\n",
    "\n",
    "    @step\n",
    "    async def summarize_document(\n",
    "        self,\n",
    "        ev: ParsedDocumentEvent,\n",
    "        ctx: Context[WorkflowState],\n",
    "        llm: Annotated[OpenAIResponses, Resource(get_llm_summary)],\n",
    "    ) -> SummaryEvent:\n",
    "        state = await ctx.store.get_state()\n",
    "        summary_prompt = state.summary_prompt\n",
    "        summary_res = await llm.acomplete(\n",
    "            f\"Please create a summary of the following document:\\n\\n'''\\n{ev.document_content}\\n'''\\n\\nFollowing these instructions: {summary_prompt}\"\n",
    "        )\n",
    "        return SummaryEvent(document_summary=summary_res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0f9fc",
   "metadata": {},
   "source": [
    "## 4. Stream Events\n",
    "\n",
    "In order to stream the internal events, we will pass `expose_internal = True` to the `stream_events` method on the workflow handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11957bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  764k  100  764k    0     0  3779k      0 --:--:-- --:--:-- --:--:-- 3764k\n"
     ]
    }
   ],
   "source": [
    "!curl https://arxiv.org/pdf/2506.05176 -L -o qwen3_embed_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ae264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue name: _done\n",
      "Queue size: 1\n",
      "Queue name: get_document_content\n",
      "Queue size: 1\n",
      "Queue name: summarize_document\n",
      "Queue size: 1\n",
      "Name of current step: get_document_content\n",
      "State of current step: preparing\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: {'state_data': {'summary_prompt': '\"\"'}, 'state_type': 'WorkflowState', 'state_module': '__main__'}\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: get_document_content\n",
      "State of current step: in_progress\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: get_document_content\n",
      "State of current step: running\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Started parsing the file under job_id 1bb03bab-9b6c-4919-a290-33e84ccedd95\n",
      ".Document has been successfully parsed!\n",
      "Name of current step: get_document_content\n",
      "State of current step: not_running\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: get_document_content\n",
      "State of current step: not_in_progress\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: {'state_data': {'summary_prompt': '\"This is a paper, so you should summarize it while still maintaining a scientific tone and its core concepts and findings\"'}, 'state_type': 'WorkflowState', 'state_module': '__main__'}\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: get_document_content\n",
      "State of current step: not_in_progress\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: get_document_content\n",
      "State of current step: exited\n",
      "Input event for current step: <class '__main__.InputDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Queue name: _done\n",
      "Queue size: 1\n",
      "Queue name: get_document_content\n",
      "Queue size: 1\n",
      "Queue name: summarize_document\n",
      "Queue size: 1\n",
      "Name of current step: summarize_document\n",
      "State of current step: preparing\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: {'state_data': {'summary_prompt': '\"This is a paper, so you should summarize it while still maintaining a scientific tone and its core concepts and findings\"'}, 'state_type': 'WorkflowState', 'state_module': '__main__'}\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: in_progress\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: running\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: not_running\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: not_in_progress\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: {'state_data': {'summary_prompt': '\"This is a paper, so you should summarize it while still maintaining a scientific tone and its core concepts and findings\"'}, 'state_type': 'WorkflowState', 'state_module': '__main__'}\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: not_in_progress\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: summarize_document\n",
      "State of current step: exited\n",
      "Input event for current step: <class '__main__.ParsedDocumentEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: <class '__main__.SummaryEvent'>\n",
      "Queue name: _done\n",
      "Queue size: 1\n",
      "Queue name: get_document_content\n",
      "Queue size: 1\n",
      "Queue name: summarize_document\n",
      "Queue size: 1\n",
      "Name of current step: _done\n",
      "State of current step: preparing\n",
      "Input event for current step: <class '__main__.SummaryEvent'>\n",
      "Workflow state at current step: {'state_data': {'summary_prompt': '\"This is a paper, so you should summarize it while still maintaining a scientific tone and its core concepts and findings\"'}, 'state_type': 'WorkflowState', 'state_module': '__main__'}\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: _done\n",
      "State of current step: in_progress\n",
      "Input event for current step: <class '__main__.SummaryEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Name of current step: _done\n",
      "State of current step: running\n",
      "Input event for current step: <class '__main__.SummaryEvent'>\n",
      "Workflow state at current step: No state reported\n",
      "Output event of current step: No output event yet\n",
      "Here is a concise scientific summary of the Qwen3 Embedding technical report, preserving its core concepts, methods, and results.\n",
      "\n",
      "Key contributions\n",
      "- Introduces the Qwen3 Embedding series (text embedding and reranking) built on Qwen3 foundation LLMs, providing three sizes for each task: 0.6B, 4B and 8B parameters.\n",
      "- Proposes a multi-stage training pipeline that leverages large-scale synthetic data generated by Qwen3 LLMs, supervised fine-tuning on high-quality labeled + filtered synthetic data, and model merging (slerp) of fine-tuning checkpoints to improve robustness and generalization.\n",
      "- Provides architecture and training details for both embedding (LLM causal model; final embedding = last-layer hidden state at [EOS]; instruction-aware inputs) and reranking (point-wise, chat-template framing; binary “yes/no” SFT objective producing a relevance probability).\n",
      "- Publishes models under an Apache 2.0 license to enable reproducibility and community use.\n",
      "\n",
      "Model architecture and training objectives\n",
      "- Embedding models: causal-attention LLMs initialized from Qwen3; instruction and query concatenated in the input context; use cosine similarity and an improved InfoNCE contrastive loss with a masking term m_ij to reduce false-negative effects and include multiple types of negatives (hard negatives, in-batch queries and documents).\n",
      "- Reranker models: single-context point-wise classification using an LLM chat prompt. Relevance score = softmax over model probabilities for “yes” vs “no”; optimized with supervised fine-tuning (cross-entropy on yes/no labels).\n",
      "- Model merging: spherical linear interpolation (slerp) across checkpoints from supervised fine-tuning to improve stability and generalization.\n",
      "\n",
      "Synthetic data and multi-stage pipeline\n",
      "- Stage 1 (weak supervision): ~150M synthetic multi-task pairs generated by Qwen3-32B (retrieval, bitext mining, STS, classification). Generation is controllable (task type, language, length, difficulty, persona/role) using a two-stage generation pipeline (configuration → query generation).\n",
      "- Stage 2 (supervised fine-tuning): mixture of labeled datasets (MS MARCO, Natural Questions, HotpotQA, NLI, Dureader, CodeSearchNet, etc.; ~7M labeled examples) plus a filtered high-quality subset of synthetic pairs (≈12M selected by cosine-similarity > 0.7).\n",
      "- Stage 3: model merging across sampled supervised checkpoints.\n",
      "- Rerankers are trained with supervised fine-tuning (no weak pretraining stage).\n",
      "\n",
      "Evaluation and main results\n",
      "- Evaluated extensively on MMTEB (Massive Multilingual Text Embedding Benchmark; 216 tasks across ~250 languages), MTEB (English v2), CMTEB (Chinese), MTEB-Code, and various retrieval/reranking benchmarks (MTEB-R, CMTEB-R, MLDR, FollowIR).\n",
      "- Embedding performance highlights:\n",
      "  - Qwen3-Embedding-8B: top-tier results (e.g., MMTEB / MTEB Multilingual mean ≈ 70.58 in reported summary; MTEB English mean 75.22; MTEB Code ≈ 80.68), outperforming many open-source baselines and surpassing prior proprietary baselines on several code and multilingual tasks (reported comparisons to Gemini Embedding, NV-Embed-v2, GTE family, E5, BGE).\n",
      "  - Qwen3-Embedding-4B also attains very strong results, close to the 8B model; Qwen3-Embedding-0.6B is competitive despite its small size.\n",
      "- Reranker performance:\n",
      "  - Qwen3-Reranker models improve top-100 candidate rankings produced by the embedding retriever. Qwen3-Reranker-0.6B already surpasses earlier rerankers; the 4B and 8B rerankers provide further gains (e.g., 4B/8B deliver the highest scores on many retrieval/reranking tasks; 8B improves ranking results by ≈3 points over the 0.6B reranker across multiple tasks in aggregate).\n",
      "- Detailed tables show consistent gains across retrieval, classification, clustering, STS and code retrieval subbenchmarks.\n",
      "\n",
      "Ablations and analysis\n",
      "- Synthetic weakly supervised pre-training is critical: models trained only with supervised data (no synthetic pretraining) exhibit clear performance drops; models trained only on synthetic data still achieve reasonable performance but benefit from supervised fine-tuning and merging.\n",
      "- Model merging yields measurable improvements: removing model merging reduces performance across benchmarks, showing its value for mitigating task/data imbalance and improving generalization.\n",
      "- The controllable synthetic-data generation (task, language, persona, difficulty) is emphasized as a key factor enabling high-quality multilingual and task-diverse pretraining.\n",
      "\n",
      "Practical features and release\n",
      "- Embedding models support flexible embedding dimensions (MRL support) and are instruction-aware (instructions can be customized for downstream tasks).\n",
      "- All Qwen3-Embedding and Qwen3-Reranker models (0.6B, 4B, 8B) are open-sourced under Apache 2.0 along with model details and evaluation results.\n",
      "\n",
      "Summary statement\n",
      "Qwen3 Embedding demonstrates that foundation LLMs can be used both as backbones and as controlled data generators to produce high-quality, multilingual, multi-task synthetic training data. Combined with multi-stage training, selective supervised fine-tuning, and model merging, this yields a family of embedding and reranking models that set or match state-of-the-art performance across broad multilingual, retrieval, and code benchmarks while offering practical, instruction-aware features across model sizes.\n"
     ]
    }
   ],
   "source": [
    "from workflows.events import StepStateChanged, EventsQueueChanged\n",
    "\n",
    "wf = SummaryWorkflow(timeout=600)\n",
    "handler = wf.run(\n",
    "    start_event=InputDocumentEvent(\n",
    "        document_path=\"qwen3_embed_paper.pdf\",\n",
    "        summary_prompt=\"This is a paper, so you should summarize it while still maintaining a scientific tone and its core concepts and findings\",\n",
    "    )\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events(expose_internal=True):\n",
    "    if isinstance(event, StepStateChanged):\n",
    "        print(\"Name of current step:\", event.name)\n",
    "        print(\"State of current step:\", event.step_state.value)\n",
    "        print(\"Input event for current step:\", event.input_event_name)\n",
    "        print(\n",
    "            \"Workflow state at current step:\",\n",
    "            event.context_state or \"No state reported\",\n",
    "        )\n",
    "        print(\n",
    "            \"Output event of current step:\",\n",
    "            event.output_event_name or \"No output event yet\",\n",
    "        )\n",
    "    elif isinstance(event, EventsQueueChanged):\n",
    "        print(\"Queue name:\", event.name)\n",
    "        print(\"Queue size:\", event.size)\n",
    "    elif isinstance(event, ParsedDocumentEvent):\n",
    "        print(\"Document has been successfully parsed!\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "result = await handler\n",
    "print(result.document_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
