{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9bd2f93"
   },
   "source": [
    "# Finance Team Assistant Agent with Classify & Exrtact\n",
    "\n",
    "In this example, we use [LlamaExtract](https://developers.llamaindex.ai/python/cloud/llamaextract/getting_started/) and [LlamaClassify](https://developers.llamaindex.ai/python/cloud/llamaclassify/getting_started/), along with [Agent Workflows](https://developers.llamaindex.ai/python/llamaagents/workflows/) to build an intelligent agent that can triage incoming emails with attachments (like invoices or expenses) and respond accordingly.\n",
    "\n",
    "This process consists of a few steps:\n",
    "1. We want to classify incoming attachments: for this demo, we're classifying invoices and expenses\n",
    "2. Next, based on what the result of the classification is, we want to extract some specific information: such as payee, due date for payment etc.\n",
    "3. Finally, we want to take action accordingly. Here, we're simulating an email acknowledgement, and we're checking expenses against a budget.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f67ca47a"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to install all the required packages and add the required API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abe487e7"
   },
   "source": [
    "### Define Data Schemas and Extraction Agents\n",
    "\n",
    "We'll define Pydantic models for the data we want to extract (Expense and Invoice) and then create LlamaExtract agents for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK8oJvQSsULW"
   },
   "outputs": [],
   "source": [
    "!pip install llama-cloud-services llama-index-workflows llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m8nb7Ka-YeW",
    "outputId": "5722a1f8-59f7-403c-9a51-c131729236ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API Key··········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"LLAMA_CLOUD_API_KEY\") is None:\n",
    "    os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass(\"Enter your LlamaCloud API Key\")\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azJF8JrcYf64"
   },
   "source": [
    "## Create Extract Agents\n",
    "\n",
    "In this scenario, we want to be able to simulate an inbox where employees or parnters can forward emails with attachments. These attachments could be invoices to be payed out, or internal expenses by employees that we need to check agains budgets etc.\n",
    "\n",
    "Below, we create out `Expense` and `Invoice` schemas that we will use as the structure of extration agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "651Xf21g9TNt"
   },
   "outputs": [],
   "source": [
    "from llama_cloud_services import LlamaExtract\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Expense(BaseModel):\n",
    "    amount: float = Field(description=\"The amount of the expense\")\n",
    "    currency: str = Field(description=\"The currency of the expense\")\n",
    "    description: str = Field(description=\"A description of the expense\")\n",
    "\n",
    "\n",
    "class Invoice(BaseModel):\n",
    "    amount: float = Field(description=\"The amount of the invoice\")\n",
    "    currency: str = Field(description=\"The currency of the invoice\")\n",
    "    due_date: str = Field(description=\"The due date of the invoice\")\n",
    "    payee: str = Field(description=\"The payee of the invoice\")\n",
    "\n",
    "\n",
    "llama_extract = LlamaExtract()\n",
    "invoice_extract_agent = llama_extract.create_agent(\n",
    "    name=\"Invoice_Extractor\", data_schema=Invoice\n",
    ")\n",
    "expense_extract_agent = llama_extract.create_agent(\n",
    "    name=\"Expense_Extractor\", data_schema=Expense\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsiTFLK0Y9iN"
   },
   "source": [
    "## Build the Agent Workflow\n",
    "\n",
    "Next, we define the custom events we want for our finance triage agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaR2CtqGsehq"
   },
   "outputs": [],
   "source": [
    "from workflows.events import StartEvent, StopEvent, Event\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "class EmailReceived(StartEvent):\n",
    "    sender: str\n",
    "    subject: str\n",
    "    body: str\n",
    "    attachment: str\n",
    "\n",
    "\n",
    "class ClassificationResult(Event):\n",
    "    classification: str\n",
    "    reason: str\n",
    "    email: str\n",
    "    attachment: str\n",
    "\n",
    "\n",
    "class SendEmail(StopEvent):\n",
    "    body: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjag8U4ZZUe_"
   },
   "source": [
    "Our final `FinanceTeamAgent` has just 2 steps:\n",
    "- `classify_email`: This is where we create a classifier with LlamaClassify, providinf rules for when an attacnhment is an invoice, vs when it's an expense\n",
    "- `extract_contents`: Which is where we can design the next steps (in this case, we're simulating sending an appropriate email) depending on what the attachment has been classified as. We use our extract agents to extract the relevant information invoices or expenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "i-e5Bt7LzCuP"
   },
   "outputs": [],
   "source": [
    "from workflows import Workflow, step\n",
    "from llama_cloud.types import ClassifierRule\n",
    "from llama_cloud_services.beta.classifier.client import ClassifyClient\n",
    "from llama_cloud.client import AsyncLlamaCloud\n",
    "\n",
    "\n",
    "class FinanceTeamAgent(Workflow):\n",
    "    def __init__(self, invoice_extract_agent, expense_extract_agent, *args, **kwargs):\n",
    "        client = AsyncLlamaCloud(token=os.environ[\"LLAMA_CLOUD_API_KEY\"])\n",
    "        self.invoice_extract_agent = invoice_extract_agent\n",
    "        self.expense_extract_agent = expense_extract_agent\n",
    "        self.llm = OpenAI(model=\"gpt-5\")\n",
    "        self.classifier = ClassifyClient(client)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    @step\n",
    "    async def classify_email(self, ev: EmailReceived) -> ClassificationResult:\n",
    "        rules = [\n",
    "            ClassifierRule(\n",
    "                type=\"invoice\",\n",
    "                description=\"This is an invoice for a contract that has to be payed out by the company. It may be forwarded from the partner or employee\",\n",
    "            ),\n",
    "            ClassifierRule(\n",
    "                type=\"expense\",\n",
    "                description=\"This is an expsense that's been submitted for a business trip that should be payed back to the employee in the next pay out cycle.\",\n",
    "            ),\n",
    "        ]\n",
    "        classification = await self.classifier.aclassify(\n",
    "            files=ev.attachment, rules=rules\n",
    "        )\n",
    "        return ClassificationResult(\n",
    "            classification=classification.items[0].result.type,\n",
    "            reason=classification.items[0].result.reasoning,\n",
    "            email=ev.sender,\n",
    "            attachment=ev.attachment,\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def extract_contents(self, ev: ClassificationResult) -> SendEmail:\n",
    "        if ev.classification == \"expense\":\n",
    "            extracted_data = await self.expense_extract_agent.aextract(ev.attachment)\n",
    "            if extracted_data.data[\"amount\"] < 1000.0:\n",
    "                body = self.llm.complete(f\"\"\"Construct an email acknowledging to {ev.email} that their expense of\n",
    "                                    {extracted_data.data[\"amount\"]} for {extracted_data.data[\"description\"]} was accepted and will be payed back in the next payment cycle.\"\"\")\n",
    "                return SendEmail(body=body.text)\n",
    "            else:\n",
    "                body = self.llm.complete(f\"\"\"Contruct an email the their expense of {extracted_data.data[\"amount\"]} for {extracted_data.data[\"description\"]} exceeds the\n",
    "                                    budget so has been denied. Explain that they can reach out if this seems wrong\"\"\")\n",
    "                return SendEmail(body=body.text)\n",
    "        elif ev.classification == \"invoice\":\n",
    "            extracted_data = await self.invoice_extract_agent.aextract(ev.attachment)\n",
    "            body = self.llm.complete(f\"\"\"Construct a reply to {ev.email}, that the invoice has been received and gibe in for on who will\n",
    "                                  be payed and how much based on the info in {extracted_data}\"\"\")\n",
    "            return SendEmail(body=body.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "vYmKqqTW2hk_"
   },
   "outputs": [],
   "source": [
    "agent = FinanceTeamAgent(\n",
    "    invoice_extract_agent=invoice_extract_agent,\n",
    "    expense_extract_agent=expense_extract_agent,\n",
    "    timeout=100.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTawjuKDZvu3"
   },
   "source": [
    "## Try the Agent\n",
    "\n",
    "To try thi agent, you can constuct an email below. Provide a file that could be an invoice or expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjtGd1JoDFdn",
    "outputId": "653686a2-55a6-41f7-c9f0-d7792be2a0ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Extracting files: 100%|██████████| 1/1 [00:05<00:00,  5.77s/it]\n"
     ]
    }
   ],
   "source": [
    "email = EmailReceived(\n",
    "    sender=\"tuana@runllama.ai\",\n",
    "    subject=\"Cowork Invoice\",\n",
    "    body=\"\",\n",
    "    attachment=\"/content/sb-receipt.png\",\n",
    ")\n",
    "\n",
    "result = await agent.run(start_event=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vL8SlFINEn6n",
    "outputId": "c9a64fa8-e6fa-415a-adb9-e7404fdfae61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: tuana@runllama.ai\n",
      "Subject: Expense Accepted – Starbucks Store #63225 (Mt. Juliet, TN) – $38.02\n",
      "\n",
      "Hi Tuana,\n",
      "\n",
      "We’ve reviewed your expense submission for $38.02 from Starbucks Store #63225 in Mt. Juliet, TN, and it has been accepted. The claim covers:\n",
      "- One Venti Mocha Latte with oat milk\n",
      "- One chocolate pie\n",
      "- One grande white mocha with dat milk\n",
      "\n",
      "Reimbursement will be included in the next payment cycle.\n",
      "\n",
      "If you have any questions, please let us know.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "[Title]\n",
      "[Company]\n",
      "[Contact Information]\n"
     ]
    }
   ],
   "source": [
    "print(result.body)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
